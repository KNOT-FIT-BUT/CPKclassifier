#Základní konfigurační soubor pro DocClassifier.
#Pro více hodnotové parametry je použita shell-like syntaxe.
#	Příklad: a "a sice" "a to" co
#Některé názvy vychází z použitých nástrojů z http://scikit-learn.org.
#----------------------------------------------------------
[DEFAULT]

#Oddělovač úrovní v hierarchii.
#Pokud má být cíl hierarchický musí jednotlivé úrovně oddělovat následující řetězec.
#Implicitní oddělovací řetězec: ->
#Příklad takového cíle: A->B
HIER_DELIMITER=->

#----------------------------------------------------------

[PREPROCESSING]
#V této sekci jsou parametry pro předzpracování dat.

#MorphoDita
DICT=./data/dicts/czech-morfflex-160310-pos_only.dict

#Udává maximální počet slov, které budou zpracovávány zaráz. (Pozor! Jako oddělovač slov je pro tento případ brán bílý znak.)
#Poku má řádek více slov, než je uvedeno zde, tak bude rozdělen na části, které se budou zpracovávat zvlášt.
#Po zpracování dojde opět ke spojení (v souboru).
#Tímto lze snížit paměťové nároky.
#Implicitně:100000
MAX_NUMBER_OF_WORDS_PER_LINE_PART=100000

#Počet procesů/vláken, které budou použity pro předzpracování.
#implicitně 1
#-1 => Automaticky dle počtu CPU.
#V multiprocesorovém režimu >1. Je jeden proces/vlákno používán pro zpracování prázdných řádků a další pro neprázdné řádky.
#Kvůli optimalizaci je to tímto způsobem, doporučuji v případě dat, kde je minimální počet prázdných řádků použít WORKERS>2.
WORKERS=

STOP_WORDS=a "a sice" "a to" aby aj ale ani aniz aniž ano asi az až bez bude budem budes budeš by byl byla byli bylo byt být ci clanek clanku clanky co coz což cz či článek článku článků články dalsi další diskuse diskuze dnes do fora fóra forum fórum ho i ja já jak jako je jeho jej jeji její jejich jen jenz jenž jeste ještě ji jí jine jiné jiz již jsem jses jseš jsme jsou jste k kam kazdy každý kde kdo kdyz když ke ktera která ktere které kteri kterou ktery který kteří ku ma má mate máte me mě mezi mi mit mít mne mně mnou muj můj muze může my na ná nad nam nám napiste napište nas nasi náš naši ne nebo necht nechť nejsou neni není nez než ni ní nic nove nové novy nový o od ode on pak po pod podle pokud polozka polozky položka položky pouze prave právě pred prede pres pri prispevek prispevku prispevky pro proc proč proto protoze protože prvni první před přede přes při příspěvek příspěvku příspěvků příspěvky pta ptá ptat ptát re s se si sice strana sve své svuj svůj svych svých svym svým svymi svými ta tak take také takze takže tato te té tedy tema téma těma temat témat temata témata tematem tématem tematu tématu tematy tématy ten tento teto této tim tím timto tímto tipy to tohle toho tohoto tom tomto tomuto toto tu tuto tvuj tvůj ty tyto u uz už v vam vám vas vase váš vaše ve vice více vsak vsechen však všechen vy z za zda zde ze ze zpet zpět zprav zpráv zprava zpráva zpravy zprávy že

#----------------------------------------------------------

[GET_DATA]
#V této sekci jsou parametry pro výběr dat. Používá se pro extrakci příznaků, přímém trénování klsifikátoru, predikci nebo
#při argumentu pro získávání dat (get data).
#Pokud je použit pro getData odstraňuje bílé znaky u plného textu a nahradí je jednou mezerou.
        
#líne vyhodnocování datových souborů True/False
LAZY_EVAL_DATA=True

#Jen data, která nemají prázdná daná pole. 
#Lze použít i na plný text stačí napsat fulltext.
NON_EMPTY=

#Jen data, která mají prázdná daná pole. 
#Lze použít i na plný text stačí napsat fulltext.
EMPTY=

#Metadatové pole, které bude použito jako cíl ke klasifikaci. Obsahuje-li více položek bude použita první. Popřípadě stačí vybrat pomocí SELECT_ITEMS.
#Pokud je toto pole vyplněno při zavolání programu s argumentem getData, vytiskne statistiku počtu dokumentů v jednotlivých cílech.
#Používá se i pro argument STATS.
#Nativně: TARGET
TARGET_FIELD=TARGET

#Metadatové pole a k němu regulární výraz. Příklad: A:"^C.*" B:"^P.*"
#Položka v poli bude vynechána pokud regulární výraz neodpovídá.
FIELD_REGEX=

#Metadatové pole a k němu minimální počet dokumentů. Příklad: A:2 B:3
#Filtr definuje minimální počet dokumentů na položku v poli.
#Pro příklad: Pokud pole obsahuje kategorii a kategorie má méně než minimální počet dokumentů, celá kategorie bude vynechána.
MIN_PER_FIELD=

#Metadatové pole a k němu maximální počet dokumentů. Příklad: A:10 B:0.8
#Filtr definuje maximální počet dokumentů na položku v poli.
#Pokud je hodnota float v intervalu (0,1), maximálně x procent (int((numberOfDcuments*x)+0.5)) dokumentů v poli bude přečteno.
MAX_PER_FIELD=

#Oddělovač (řetězec), který separuje položky v poli.
ITEM_DELIMITER=$|$

#Vybrání slov v každém dokumentu. (jedná se o python selector)
#příklady:
#0		- vybere jen každé první slovo
#2-10	- vybere v každém dokument 3. až 10. slovo
#10-	- vybere 11. slovo a všechny další slova do konce dokumentu
SELECT_WORDS=

#Výběr položek v poli. Formát: pole:výběr
#	(výběr: jedná se o python selector)
#Příklad: A:0 B:2-10 C:10-
#	1. položka, 3.-10. položka, 11. položka a další až do konce
SELECT_ITEMS=

#Určuje jestli má být zahrnutý plný text(data) True/False
#Používá se pro trénování, predikci ale i při argumentu getData.
GET_FULLTEXT=True


#Názvy vybraných metadatových polí. 
#Používá se pro trénování, predikci ale i při argumentu getData.
#Vyhrazené jméno a nesmí se používat: fulltext
#Vytvoření kopie dat s novým názvem, lze udělat následovně:
#	PUVODNI:NOVY
#	Příklad:
#		Chci vytvořit kopii dat: nazev.
#		Pro vytvoření kopie s novým názvem bude vypadat formát takto:
#			GET_META_FIELDS=nazev:novyNazev
#Konkatenace:
#	A+B+C:A_B_C
#Musíme přiřadit název konkatenovaným datům. Pokud není přiřazeno nové jméno bere se jako celý název jednoho pole.

GET_META_FIELDS=


#----------------------------------------------------------
[FEATURES]
#Nastavení pro extrakci příznaků.
#Dostupné nástroje pro vektorizaci:
#	Doc2Vec
#	CountVectorizer
#	TfidfVectorizer
#	HashingVectorizer		(nepoužívá slovník)
#	MatchTargetVectorizer
#		Vytváří vektor na základě shodnosti slov v daném cíli.
#		Vytvoří příznakový vektor, kde jednotlivé dimenze odrážejí jednotlivé cíle/třídy/y. Cíle jsou pro vnitřní účely lemmatizováný a dochází k separaci znaků (.,: atd).
#		Hodnoty v těchto dimenzích pak ukazují kolik shodných slov (k tomu danému cíli) je ve vzorku obsaženo.
#		    Příklad:
#		        Popis dimenzí:
#		        	0.    Cíl obsahuje slova: A C D
#		        	1.    Cíl obsahuje slova: B G F
#        
#		        Vzorek:
#		        	A A A B B A C
#        
#		        Výsledný vektor:
#		        	[5 2]
#
#Dostupné analyzátory:
#	Fulltext:
#		ngram		-	Tvoří ngramy ze slov. Parametr délka.
#	Metadata:
#		ngram		-	Tvoří ngramy ze slov. Parametr délka. (separátně pro každou položku v metadatovém poli)
#		wholeItem	-	bere celou položku v metadatovém poli jako celek. Bez parametru (bude ignorován). 
#
#	Parametr pro ngram se odděluje pomocí / tedy například pro bigramy: ngram/2, nebo jednotlivá slova: ngram/1

#Nástroj pro vektorizaci pro plný text.
#Pokud je vynechán automaticky se doplní HashingVectorizer
FULL_TEXT_VECTORIZER=

#Definuje na jakých datech si má FULL TEXT VECTORIZER vybudovat slovník.
#Taková data nemusí být nutně uvedena v GET_DATA.
#Implicitně fulltext
FULL_TEXT_VECTORIZER_BUILD_VOCABULARY_ON=

#Analyzátor pro plný text
#Pokud je tento parametr prázdný použije se automaticky: ngram/1.
FULL_TEXT_ANALYZER=

#Pokud pro nějaká metadata (v GET_META_FIELDS) není uveden nástroj pro vektorizaci, použije se automaticky TfidfVectorizer.
#Formát: jméno_pole:nástroj_pro_vektorizaci
META_VECTORIZERS=

#Definuje na jakých datech si má Daný druh metadat vybudovat slovník vybudovat slovník.
#Formát: jméno_pole:jméno_pole_pro_budování_slovníku
#Implicitně je použit stejný druh dat.
#Data pro budování slovníku nemusí být nutně uvedena v GET_DATA.
META_VECTORIZERS_BUILD_VOCABULARY_ON=

#Pokud pro nějaká metadata (v GET_META_FIELDS) není uveden analyzátor, použije se automaticky ngram/1.
#Formát: jméno_pole:analyzátor
META_ANALYZERS=

#Pokud je True, tak nebudou brána v úvahu při trénování/predikci data, která jsou prázdná.
#Tedy například pro data se dvěma poli s názvem: Název a Autor. Jsou natrénovány klasifikátory na těchto datech:
#	Název	Autor
#1.	A
#2.			B
#První dokument bude brán v úvahu při trénování pouze u klasifikátoru pro Název, ale ne pro Autora. Obdobně druhý dokument,
#bude použit pro trénování pouze klasifikátoru pro Autora.
#
#Dále pokud budeme chtít predikovat bude situace následující:
#	Název	Autor
#1. A		B		Pro predikci použije oba klasifikátory.
#2.	A				Pro predikci použije pouze jeden z klasifikátorů. Výsledky jistot (pro USE_PROB=True) pro jednotlivé cíle pro Autor jsou nastaveny na nula.
#3.			B		Pro predikci použije pouze jeden z klasifikátorů. Výsledky jistot (pro USE_PROB=True) pro jednotlivé cíle pro Název jsou nastaveny na nula.
#4.					Nejsou poskytnuta data, nepoužije ani jeden klasifikátor, vráti prázdný výsledek.
#
#Implicitně: True
SKIP_EMPTY=


#Udává maximálně počet procesů, které se budou podílet na extrakci příznaků.
#Implicitně:1
#-1 => Automaticky dle počtu CPU.
WORKERS=

#----------------------------------------------------------
[CLASSIFICATION]
#Nastavení pro trénování klasifikátoru
#Extrakce příznaků v sekci FEATURES. Výběr dat v GET_DATA.

#Dostupné klasifikátory.
#	MultinomialNB	-	Vhodné používat pouze s diskrétními hodnotami. Jako jsou počty slov (CountVectorizer).
#	SVC
#	LinearSVC
#	KNeighborsClassifier
#	SGDClassifier
#	MatchTargetClassifier	-	Vhodné v kombinaci s MatchTargetVectorizer.
#		-	Klasifikuje na základě slov, které se vyskytují v daném cíli. Cíle jsou pro vnitřní účely lemmatizovány a dochází k separaci znaků (.,: atd).
#			Tedy například pokud budeme klasifikovat na základě názvu dokumentu, tak pro cíle/kategorie s názvy:
#				matematika
#				beletrie
#			Klasifikuje dokument s názvem (lemmatizovaná podoba):
#				matematika pro základní škola
#			Do kategorie matematika, na základě shody slova matematika.


# Přiřazení klasifikátorů k datům z GET_META_FIELDS a fulltextu.
# Pokud je druh dat vynechán automaticky se doplní LinearSVC.
# Pokud je zvolen MultinomialNB a pro extrakci příznaků je použito Doc2Vec nebo HashingVectorizer s NON_NEGATIVE=false, dojde
# k chybě, protože příznaky mohou mít záporné hodnoty, které MultinomialNB nezvládne. Proto v takovýchto případech použijte jiný
# klasifikátor.
# Váhy jsou implicitně 1.
#	Pokud je zadán místo čísla řetězec auto. Bude váha automaticky získána na základě úspěšnosti klasifikátoru na trénovací sadě dat.
#	Narozdíl od váhy zadané číslem je tímto způsobem možné získat pro každou natrénovanou kategorii jinou váhu.
#	Zohledňuje také počet natrénovaných kategorií daným klasifikátorem z celkového počtu kategorií.
# Práh je implicitně 0 a udává nejmenší přijatelnou hodnotu jistoty klasifikátoru, která bude brána v úvahu. Jistota je brána před vážením.
#	Tedy pro práh například 0.5. Budou všechny hodnoty pod (bez) 0.5 nastaveny na 0.
#	Uplatňuje se pouze v kombinaci USE_PROB=True.
# Formát: jméno_dat:název_klasifikátoru:váha:práh
# Jméno dat vyhrazené pro plný text: fulltext
# Příklad:
#	A:SVC:0.8:0 B:KNeighborsClassifier:0.5:0.3 B:MultinomialNB:0.3:0.3
CLASSIFIER=


#Pro nevyvážené datasety je možné vyvážit trénovací množinu. Lze použít nějakou z metod vyvažování:
#	RandomUnderSampling	-	Náhodně vybere dokumenty a odstraní je, dokud nebude splněna podmínka pro maximální počet dokumentů v kategorii.
#							Parametrem je číslo od (0,1>, které určuje maximální počet dokumentů v kategorii.
#								Výpočet nového maximálního počtu dokumentů: parametr*(maximální počet dokumentů vkategorii)
#	RandomOverSampling	-	Náhodně vybere dokumenty a naklonuje je. Klonuje tím způsobem, aby vytvořil odpovídající počet dokumentů.
#							Parametrem je kladné číslo které určuje minimální počet dokumentů v kategorii.
#								Výpočet nového minimálního počtu dokumentů: parametr*(maximální počet dokumentů vkategorii)
#
#Příklad:
#	RandomUnderSampling:0.5 RandomOverSampling:0.5
#	
#	Příklad ukazuje použití dvou metod zároveň. Metody jsou aplikovány v pořadí v jakém jsou uvedeny.
#	Každá metoda v řadě pracuje s výstupem předchozí metody (až na první). Tedy konkrétně v tomto případě
#	se vezme polovina(0.5) z výstupu RandomUnderSampling.

BALANCING=

#Udává maximálně počet klasifikátorů, které budou zároveň trénovány.
#Implicitně:1
#-1 => Automaticky dle počtu CPU.
WORKERS=

#Udává počet křížově validačních kroků při získávání vah automaticky (pokud má klasifikátor uvedeno jako váhu hodnotu auto).
#Implicitně: 4
#Minimálně
#Pro rozdělování testovací/trénovací množiny je použito: StratifiedKFold.
WEIGHT_AUTO_CV=

#----------------------------------------------------------
[PREDICTION]
#Nastavení pro predikci cílů.
#Výběr dat v GET_DATA.


#Název pole, kde bude uložen predikovaný cíl.
#Používá se i pro argument STATS.
#Nativně: PREDICTED
PREDICTED_FIELD_NAME=

#Vypíše až NBEST nejlepších cílů.
#Očekává celé číslo. Implicitně 1.
N_BEST=

#Prefix pro názvy polí, které budou obsahovat N nejlepších cílů.
#Nativní: BEST_
#Příklad:
#	Pro: BEST_ pří N=3
#	Vytvoří sloupce: best_2 a best_3
#		Nejlepší (1) je predikovaný cíl.
N_BEST_PREFIX=

#Postfix pro názvy polí, které budou obsahovat jistotu/y pro predikovaný/é cíl/e.
#Pokud není uvedeno nevypisuje tyto pole.
#Příklad:
#	Pro: _VAL pří N_BEST=3 N_BEST_PREFIX=BEST_ a PREDICTED_FIELD_NAME=PREDICTED
#	Vytvoří sloupce: PREDICTED_VAL best_2_VAL a best_3_VAL
CONF_POSTFIX=

#Názvy sloupců metadat.
#Lze použít pro vypsání dodatečných informací k predikovanému cíli. Například id dokumentu.
#Formát názvy metadatových polí. Příklad: A B C D
WRITE_META_FIELDS=

#Použití pravděpodobností příslušnosti dokumentu k daným kategoriím.
#Musí být True, pokud chceme N nejpravděpodnějších kategorií/cílů.
#Pokud je false je použito následující slučování:
#		Vezmou se všechny predikované cíle z daných klasifikátorů a sčítají se váhy u stejně predikovaných 
#		cílů. Vybrán je cíl s největší výslednou váhou.
#		Příklad:
#			Predikce pro dokument: cílA s váhou 0.3, cílA s váhou 0.4 cílB s váhou 0.6
#			Výsledek: cílA
#	Je vhodné použít alespoň 3 druhy dat.
#Hodnoty: True/False
#Implicitně: True
USE_PROB=True

#Využívá se pouze pokud je USE_PROB =true.
#Pokud je výsledek predikován s menší jistotou než-li je práh(THRESHOLD), tak je výsledek brán jako neklasifikovaný.
#Implicitně: 0
THRESHOLD=


#Udává počet procesů podílejících se na predikci.
#Implicitně:1
#-1 => Automaticky dle počtu CPU.
WORKERS=

#----------------------------------------------------------
[TESTING]
#Nastavení pro testování klasifikátoru.
#Predikování se řídí nastavením v sekci PREDICTION. Trénování klasifikátoru se řídí nastavením v CLASSIFICATION.
#Extrakce příznaků v sekci FEATURES. Výběr dat v GET_DATA.

#Metody:
#	LeaveOneOut				-	Tvoří trénovací množinu jako všechny dokumenty až na jeden.
#								Ten jeden bude v testovací množině. Takto se v testovací množině prostřídají všechny dokumenty.
#								Počet iterací je tedy roven počtu dokumentů.
#	KFold					-	Rozdělí množinu dokumentů na k (k dle SPLITS) částí jednu část použje pro testování a zbylé pro trénování.
#	StratifiedKFold			-	Implicitní. Tvoří trénovací a testovací množinu se zachováním procenta vzorků v každém cíli.
#	StratifiedShuffleSplit	-	Tvoří trénovací a testovací množinu se zachováním procenta vzorků v každém cíli. Negarantuje, že každá část bude odlišná.

SPLIT_METHOD=StratifiedKFold

#Název pole, kde bude uvedeno, zda-li se jedná o správný výsledek predikce.
#Používa se při vypisování výsledků.
#	Hodnoty tohoto pole: 0 neopdovídá, 1 odpovídá.
#Pokud není uveden, toto pole se nevypíše.
PREDICT_MATCH_FIELD_NAME=

#Kolikrát se má vytvořit trénovací a testovací množina. Určuje počet iterací při křížové validaci.
#Implicitně 4.
#Ignoruje se pro LeaveOneOut.
SPLITS=4

#Velikost testovací množiny. Číslo v intervalu (0,1) procento z počtu. Celé číslo >=1 je počet.
#Implicitně 0.25.
#Pouze pro: StratifiedShuffleSplit
TEST_SIZE=0.25


#----------------------------------------------------------
[STATS]
#Nastavení pro získávání statistik, ze souboru vzniklého z predikce.
#Používá nastavení filtrování ze sekce GET_DATA.

#Název pole, kde je uložen pravý cíl.
#Pokud je toto pole použito společně s PREDICTED_FIELD_NAME, tak jsou
#zobrazeny statistiky, znázorňující úspěšnost.
#Nativně: TARGET
TARGET_FIELD_NAME=

#Název pole, kde je uložen predikovaný cíl.
#Pokud je toto pole použito společně s TARGET_FIELD_NAME, tak jsou
#zobrazeny statistiky, znázorňující úspěšnost.
#Nativně: PREDICTED
PREDICTED_FIELD_NAME=

#----------------------------------------------------------
[DOC2VEC]

#Počet dimenzí vektoru.
#Implicitně 500
SIZE=500

#Počáteční rychlost učení(learning rate) (bude lineárně klesat k nule).
#Implicitně 0.025
ALPHA=0.025

#Maximální vzdálenost mezi predikovaným slovem a kontextovými slovy použita pro predikci v dokumentu.
#Implicitně 5
WINDOW=5

#Ignoruje všechny slova s celkovou frekvencí menší než je tato.
#Implicitně 5
MIN_COUNT=5

#Udává počet procesů/vláken pro trénování modelu.
#Implicitně 1
WORKERS=1

#Počet iterací/epoch.
#Implicitně 10
ITER=10

#Prahová hodnota pro snížení vzorků slov s vysokou frekvencí.
#Implicitně 0 (vypnuto).
#Použitelná hodnota 1e-5.
SAMPLE=0

#Jaký má být použit algoritmus:
#DM=1, ‘distributed memory’ (PV-DM
#Jinak distributed bag of words (PV-DBOW).
#Implicitně 1.
DM=1

#if > 0, bude použito negativní vzorkování, celočíselná hodnota udává kolik “noise words” má být odstraněno (obvykle 5-20)
#Implicitně 0.
NEGATIVE=0
                 
#----------------------------------------------------------

[HASHING_VECTORIZER]
#Nastavení nástroje pro vektorizaci.

#(True/False)Určuje jestli výstupní matice má obsahovat pouze nezáporné hodnoty. True vhodné například pro klasifikátor MultinomialNB.
NON_NEGATIVE=True

#Udává počet příznaků. Moc malé číslo může způsobovat příliš mnoho kolizí (po zaheshování).
N_FEATURES=65536

#----------------------------------------------------------

[K_NEIGHBORS_CLASSIFIER]
#Nastavení klasifikátoru k nejbližších sousedů.

#Počet sousedů. Implicitně 3.
NUM_OF_NEIGHBORS=3

#Způsob váhování bodů.
#Možno použít:
#	uniform		Všechny body ve všech sousedstvích mají stejnou váhu.
#	distance	Body jsou váhovány vzhledem ke vzdálenosti. Bližší body mají větší váhu.
#Implicitně distance.
WEIGHTS=distance

#Udává počet vláken pro hledání sousedů.
#-1 použije všechny dostupné.
#Implicitně 1.
WORKERS=1

[SGD_CLASSIFIER]
#Nastavení pro SGDClassifier
#Více informací přímo v: http://scikit-learn.org.

#Například: hinge nebo log
#Implicitně hinge.
loss=





